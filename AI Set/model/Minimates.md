---
tags:
  - model/数字角色
created: 2024-12-16
source: https://github.com/kleinlee/MiniMates
description: 支持cpu推理， 支持云端API调用， 推理速度快，轻量，one-shot
---

## 速度

以下是 MiniMates 数字人算法在不同设备和推理框架下的fps表现(纯粹推理耗时)：

|设备|推理框架|fps|
|---|---|---|
|Intel i5 12600k|ncnn-cpu|11|
|AMD Ryzen7 7735H|ncnn-cpu|10|
|RTX4050 laptop|ncnn-vulkan|119|
|mac m1|ncnn-cpu|36|
|RTX3080|ncnn-vulkan|100|
|Intel graphics 770|ncnn-vulkan|18|
|mac m1|ncnn-vulkan|66|
|RTX3080|pytorch-gpu|374|

## 算法介绍

> MiniMates 采用 coarse-to-fine 的 wrap network 架构，取代传统的 dense motion 方法，以实现在 CPU 上的性能提升。 此外，MiniMates还使用 显式的 UV map 技术来提高人像的精度。 

![](figures/Pasted%20image%2020241216160430.png)


在图像生成和驱动任务（如数字人驱动）中，**coarse-to-fine 的 wrap network 架构**与**传统的 dense motion 方法**是两种实现动态形变和图像合成的核心技术。它们在实现原理、计算复杂度以及适用场景方面各有特点。以下是详细的对比和介绍：

---

### **1. Coarse-to-Fine 的 Wrap Network 架构**

#### **核心思想：**

- **逐步细化：** 采用从粗到细（coarse-to-fine）的策略，通过多层次的形变（warping）网络，逐步将驱动源（如语音或表情）生成的特征映射到目标图像。
- **局部优化：** 在每个层次逐渐对细节进行补充，最终实现高精度的结果。

#### **工作流程：**

1. **Coarse Stage（粗级）：**
    
    - 进行全局形变建模，生成初步的人像或图像形态。
    - 捕捉大范围的特征，如面部的整体位置和轮廓。
2. **Fine Stage（细级）：**
    
    - 逐层细化形变结果，对局部细节（如眼睛、嘴巴）进行精确调整。
    - 引入更高分辨率的纹理、表情变化或微表情。
3. **UV Map 技术：**
    
    - **显式 UV Map** 提供了统一的纹理映射方式，将人脸表面特征直接映射到二维平面上。
    - 提高了面部特征细节的生成精度，并解决了传统方法中可能出现的纹理扭曲问题。

#### **优点：**

- **计算效率高：**
    - 采用逐步优化的方法，避免了处理大规模特征图所需的高计算开销。
    - 在 CPU 上的性能表现显著提升，支持实时运行。
- **模块化设计：**
    - 各级网络可以分别优化，便于在不同设备上实现灵活的性能调优。
- **精细控制：**
    - 从粗到细的架构便于控制生成细节，使生成的图像在大范围和局部细节上都具有较高的质量。

#### **应用场景：**

- 语音驱动的数字人生成。
- 表情驱动的实时虚拟形象控制。
- CPU 或低算力设备上的实时图像生成。

---

### **2. 传统的 Dense Motion 方法**

#### **核心思想：**

- 直接对整个图像或特征图进行逐像素的运动场估计（dense motion estimation），通过复杂的形变场（motion field）生成驱动结果。

#### **工作流程：**

1. **Motion Field 估计：**
    
    - 使用深度网络预测目标图像的像素级运动场。
    - 每个像素对应的运动向量指示其如何从源图像形变到目标图像。
2. **形变与生成：**
    
    - 根据预测的 dense motion field，将源图像的每个像素位置形变到目标图像的位置。
    - 通过重采样和生成网络补充细节。

#### **优点：**

- **细粒度控制：**
    - Dense motion 方法直接对每个像素的运动进行建模，理论上可以生成更精细的动态效果。
- **广泛适用：**
    - 适用于各种形变场景，如任意视角转换、动作驱动等。

#### **缺点：**

- **计算开销高：**
    
    - Dense motion field 的逐像素计算需要大量的算力，通常依赖于 GPU。
    - 对大分辨率图像的处理速度较慢，难以在实时场景中应用。
- **对资源依赖强：**
    
    - 无法高效运行于低算力设备（如普通电脑或移动设备）。

#### **应用场景：**

- 高分辨率图像生成。
- 深度优化的服务器端生成系统。

---

### **3. 两者的对比**

|**特性**|**Coarse-to-Fine Wrap Network**|**Dense Motion 方法**|
|---|---|---|
|**计算效率**|高效，可在 CPU 上实时运行|计算开销高，通常需要 GPU 支持|
|**适用场景**|低算力设备，实时生成|高分辨率场景，非实时生成|
|**精细化程度**|从粗到细逐步提升，局部细节丰富|全局逐像素建模，细粒度高但代价大|
|**模型复杂度**|较低，采用分层设计，便于优化|高复杂度，难以在低资源环境下运行|
|**对硬件的依赖性**|较低，普通电脑或嵌入式设备即可运行|较高，依赖高性能计算资源|
|**适配性**|可灵活调整精细化级别，适配多种设备性能|对模型大小和资源需求较固定|

---

### **总结**

- **Coarse-to-Fine 的 Wrap Network 架构**通过逐步优化策略，显著降低了计算需求，非常适合实时、低算力场景，尤其是在普通电脑上驱动数字人的应用。
- **Dense Motion 方法**更适合需要高分辨率和极高细节的场景，但其计算开销和资源需求限制了在实时应用中的普及。

**MiniMates** 的成功结合了 **Coarse-to-Fine Wrap Network** 和 **UV Map 技术**，实现了实时、高效、精细的人像驱动效果，在低算力环境下具有强大的竞争力。